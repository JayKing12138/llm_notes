{
    "name": "Qwen3-4B-Instruct-2507-gsm8k_zh-eval@ceval",
    "dataset_name": "ceval",
    "dataset_pretty_name": "C-Eval",
    "dataset_description": "C-Eval is a benchmark designed to evaluate the performance of AI models on Chinese exams across various subjects, including STEM, social sciences, and humanities. It consists of multiple-choice questions that test knowledge and reasoning abilities in these areas.",
    "model_name": "Qwen3-4B-Instruct-2507-gsm8k_zh-eval",
    "score": 0.7823,
    "metrics": [
        {
            "name": "mean_acc",
            "num": 1346,
            "score": 0.7823,
            "macro_score": 0.7851,
            "categories": [
                {
                    "name": [
                        "Humanities"
                    ],
                    "num": 257,
                    "score": 0.7743,
                    "macro_score": 0.7693,
                    "subsets": [
                        {
                            "name": "modern_chinese_history",
                            "score": 0.8261,
                            "num": 23
                        },
                        {
                            "name": "ideological_and_moral_cultivation",
                            "score": 0.8947,
                            "num": 19
                        },
                        {
                            "name": "logic",
                            "score": 0.7727,
                            "num": 22
                        },
                        {
                            "name": "law",
                            "score": 0.7083,
                            "num": 24
                        },
                        {
                            "name": "chinese_language_and_literature",
                            "score": 0.7391,
                            "num": 23
                        },
                        {
                            "name": "art_studies",
                            "score": 0.7879,
                            "num": 33
                        },
                        {
                            "name": "professional_tour_guide",
                            "score": 0.931,
                            "num": 29
                        },
                        {
                            "name": "legal_professional",
                            "score": 0.4783,
                            "num": 23
                        },
                        {
                            "name": "high_school_chinese",
                            "score": 0.4737,
                            "num": 19
                        },
                        {
                            "name": "high_school_history",
                            "score": 0.85,
                            "num": 20
                        },
                        {
                            "name": "middle_school_history",
                            "score": 1.0,
                            "num": 22
                        }
                    ]
                },
                {
                    "name": [
                        "Other"
                    ],
                    "num": 384,
                    "score": 0.6953,
                    "macro_score": 0.7169,
                    "subsets": [
                        {
                            "name": "civil_servant",
                            "score": 0.7021,
                            "num": 47
                        },
                        {
                            "name": "sports_science",
                            "score": 0.8947,
                            "num": 19
                        },
                        {
                            "name": "plant_protection",
                            "score": 0.8182,
                            "num": 22
                        },
                        {
                            "name": "basic_medicine",
                            "score": 0.7895,
                            "num": 19
                        },
                        {
                            "name": "clinical_medicine",
                            "score": 0.6364,
                            "num": 22
                        },
                        {
                            "name": "urban_and_rural_planner",
                            "score": 0.6957,
                            "num": 46
                        },
                        {
                            "name": "accountant",
                            "score": 0.5714,
                            "num": 49
                        },
                        {
                            "name": "fire_engineer",
                            "score": 0.7097,
                            "num": 31
                        },
                        {
                            "name": "environmental_impact_assessment_engineer",
                            "score": 0.7419,
                            "num": 31
                        },
                        {
                            "name": "tax_accountant",
                            "score": 0.5918,
                            "num": 49
                        },
                        {
                            "name": "physician",
                            "score": 0.7347,
                            "num": 49
                        }
                    ]
                },
                {
                    "name": [
                        "STEM"
                    ],
                    "num": 430,
                    "score": 0.8233,
                    "macro_score": 0.8293,
                    "subsets": [
                        {
                            "name": "computer_network",
                            "score": 0.7895,
                            "num": 19
                        },
                        {
                            "name": "operating_system",
                            "score": 1.0,
                            "num": 19
                        },
                        {
                            "name": "computer_architecture",
                            "score": 0.9524,
                            "num": 21
                        },
                        {
                            "name": "college_programming",
                            "score": 0.8649,
                            "num": 37
                        },
                        {
                            "name": "college_physics",
                            "score": 0.8421,
                            "num": 19
                        },
                        {
                            "name": "college_chemistry",
                            "score": 0.75,
                            "num": 24
                        },
                        {
                            "name": "advanced_mathematics",
                            "score": 0.7895,
                            "num": 19
                        },
                        {
                            "name": "probability_and_statistics",
                            "score": 0.8333,
                            "num": 18
                        },
                        {
                            "name": "discrete_mathematics",
                            "score": 0.4375,
                            "num": 16
                        },
                        {
                            "name": "electrical_engineer",
                            "score": 0.5946,
                            "num": 37
                        },
                        {
                            "name": "metrology_engineer",
                            "score": 0.75,
                            "num": 24
                        },
                        {
                            "name": "high_school_mathematics",
                            "score": 0.7222,
                            "num": 18
                        },
                        {
                            "name": "high_school_physics",
                            "score": 0.8947,
                            "num": 19
                        },
                        {
                            "name": "high_school_chemistry",
                            "score": 0.8947,
                            "num": 19
                        },
                        {
                            "name": "high_school_biology",
                            "score": 0.8421,
                            "num": 19
                        },
                        {
                            "name": "middle_school_mathematics",
                            "score": 1.0,
                            "num": 19
                        },
                        {
                            "name": "middle_school_biology",
                            "score": 0.9048,
                            "num": 21
                        },
                        {
                            "name": "middle_school_physics",
                            "score": 0.9474,
                            "num": 19
                        },
                        {
                            "name": "middle_school_chemistry",
                            "score": 0.95,
                            "num": 20
                        },
                        {
                            "name": "veterinary_medicine",
                            "score": 0.8261,
                            "num": 23
                        }
                    ]
                },
                {
                    "name": [
                        "Social Science"
                    ],
                    "num": 275,
                    "score": 0.8473,
                    "macro_score": 0.8671,
                    "subsets": [
                        {
                            "name": "college_economics",
                            "score": 0.7273,
                            "num": 55
                        },
                        {
                            "name": "business_administration",
                            "score": 0.7273,
                            "num": 33
                        },
                        {
                            "name": "marxism",
                            "score": 0.9474,
                            "num": 19
                        },
                        {
                            "name": "mao_zedong_thought",
                            "score": 0.875,
                            "num": 24
                        },
                        {
                            "name": "education_science",
                            "score": 0.8621,
                            "num": 29
                        },
                        {
                            "name": "teacher_qualification",
                            "score": 0.9091,
                            "num": 44
                        },
                        {
                            "name": "high_school_politics",
                            "score": 0.9474,
                            "num": 19
                        },
                        {
                            "name": "high_school_geography",
                            "score": 0.8421,
                            "num": 19
                        },
                        {
                            "name": "middle_school_politics",
                            "score": 1.0,
                            "num": 21
                        },
                        {
                            "name": "middle_school_geography",
                            "score": 0.8333,
                            "num": 12
                        }
                    ]
                }
            ]
        }
    ],
    "analysis": "N/A"
}