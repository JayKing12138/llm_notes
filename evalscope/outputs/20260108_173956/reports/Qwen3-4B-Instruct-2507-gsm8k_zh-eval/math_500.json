{
    "name": "Qwen3-4B-Instruct-2507-gsm8k_zh-eval@math_500",
    "dataset_name": "math_500",
    "dataset_pretty_name": "MATH-500",
    "dataset_description": "MATH-500 is a benchmark for evaluating mathematical reasoning capabilities of AI models. It consists of 500 diverse math problems across five levels of difficulty, designed to test a model's ability to solve complex mathematical problems by generating step-by-step solutions and providing the correct final answer.",
    "model_name": "Qwen3-4B-Instruct-2507-gsm8k_zh-eval",
    "score": 0.8106,
    "metrics": [
        {
            "name": "mean_acc",
            "num": 433,
            "score": 0.8106,
            "macro_score": 0.8106,
            "categories": [
                {
                    "name": [
                        "default"
                    ],
                    "num": 433,
                    "score": 0.8106,
                    "macro_score": 0.8322,
                    "subsets": [
                        {
                            "name": "Level 1",
                            "score": 0.9767,
                            "num": 43
                        },
                        {
                            "name": "Level 2",
                            "score": 0.9444,
                            "num": 90
                        },
                        {
                            "name": "Level 3",
                            "score": 0.87,
                            "num": 100
                        },
                        {
                            "name": "Level 4",
                            "score": 0.77,
                            "num": 100
                        },
                        {
                            "name": "Level 5",
                            "score": 0.6,
                            "num": 100
                        }
                    ]
                }
            ]
        }
    ],
    "analysis": "N/A"
}